{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA06MXiTPxye"
      },
      "source": [
        "Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pz2wUp_P0if",
        "outputId": "0047c5c7-4760-4421-bd07-f879208b4eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentiment_analysis_nal'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 33\u001b[K\n",
            "Receiving objects: 100% (33/33), 1.19 MiB | 7.78 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/danielphamvt/sentiment_analysis_nal.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1s8MaF9GQFYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e58c0a-7689-429e-eab7-2f42408ddd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘dataSA’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir dataSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jUXRxudlQSJl"
      },
      "outputs": [],
      "source": [
        "!mv /content/sentiment_analysis_nal/data_clean/train.crash /content/dataSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mp2-sxCnQbwz"
      },
      "outputs": [],
      "source": [
        "!mv /content/sentiment_analysis_nal/data_clean/test.crash /content/dataSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VLh4Xj-TQfjR"
      },
      "outputs": [],
      "source": [
        "!rm -r sentiment_analysis_nal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuRZB1naPrwM"
      },
      "source": [
        "Prepare transformer and library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-buyo7gvpQq",
        "outputId": "bf0e30d4-9953-40ce-8fbf-7177bdc54efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QtXYSLiLv6J1"
      },
      "outputs": [],
      "source": [
        "# !cd transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS_nadJ1wJi_",
        "outputId": "2c632309-a494-4d78-dcba-90f6453d20c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install fastBPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBivOrmU5HpC",
        "outputId": "c7498488-2618-4ea8-81b8-ec97d7f5cc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.10/dist-packages (24.0)\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# cant install fairseq with pip 24.2\n",
        "!pip install pip==24.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lMbTeAh3gfR",
        "outputId": "fbc3dead-1a53-416a-b3fd-8d8f67a84df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.10)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2024.5.15)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.4)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.9.2)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.26.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.10.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq) (12.5.82)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0zfddNB9uIE"
      },
      "source": [
        "fastBPE is a tool for efficient tokenization using the BPE algorithm, while fairseq is a versatile toolkit for training and deploying state-of-the-art NLP models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_gMbjTLxsxG",
        "outputId": "939efc92-40f8-41e6-825c-bda13d65332b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srH-mjh7yI62",
        "outputId": "e7f053de-b6dd-45af-95db-529c9286de3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vncorenlp in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2024.7.4)\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m--2024-07-31 16:35:17--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412575 (26M) [application/octet-stream]\n",
            "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
            "\n",
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   147MB/s    in 0.2s    \n",
            "\n",
            "2024-07-31 16:35:17 (147 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
            "\n",
            "--2024-07-31 16:35:17--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 526544 (514K) [application/octet-stream]\n",
            "Saving to: ‘vi-vocab’\n",
            "\n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-07-31 16:35:17 (10.2 MB/s) - ‘vi-vocab’ saved [526544/526544]\n",
            "\n",
            "--2024-07-31 16:35:17--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128508 (125K) [text/plain]\n",
            "Saving to: ‘wordsegmenter.rdr’\n",
            "\n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-07-31 16:35:17 (4.88 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install the vncorenlp python wrapper\n",
        "!pip install vncorenlp\n",
        "\n",
        "# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter)\n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/\n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mJ4mAC8RyaAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed69dcd3-9716-4dbc-81cf-b51fe3d71c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Tôi', 'là', 'học_sinh', 'của', 'trường', 'Khoa_học_Tự_Nhiên', 'TPHCM', '.'], ['Tôi', 'thích', 'mèo', '.']]\n"
          ]
        }
      ],
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "rdrsegmenter = VnCoreNLP(\"/content/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "\n",
        "text = \"Tôi là học sinh của trường Khoa học Tự Nhiên TPHCM. Tôi thích mèo.\"\n",
        "\n",
        "word_segmented_text = rdrsegmenter.tokenize(text)\n",
        "print(word_segmented_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ2fApol0Pc-"
      },
      "source": [
        "rdrsegmenter is basically the word tokenizer for vnmese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KluIErK0bpO"
      },
      "source": [
        "Note that the tokenizer can split between sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLB-CEA70UrK",
        "outputId": "f28c585b-bca6-486e-c462-d59f44953238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-31 16:35:24--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 18.160.41.47, 18.160.41.104, 18.160.41.77, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|18.160.41.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243308020 (1.2G) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_fairseq.tar.gz.1’\n",
            "\n",
            "PhoBERT_base_fairse 100%[===================>]   1.16G  85.1MB/s    in 13s     \n",
            "\n",
            "2024-07-31 16:35:37 (90.9 MB/s) - ‘PhoBERT_base_fairseq.tar.gz.1’ saved [1243308020/1243308020]\n",
            "\n",
            "PhoBERT_base_fairseq/\n",
            "PhoBERT_base_fairseq/bpe.codes\n",
            "PhoBERT_base_fairseq/model.pt\n",
            "PhoBERT_base_fairseq/dict.txt\n"
          ]
        }
      ],
      "source": [
        "# installing the pretrain for phoBERT\n",
        "!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
        "!tar -xzvf PhoBERT_base_fairseq.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLrwpA-W1P3D",
        "outputId": "ef4f197c-87a7-4c03-a2c7-0342e5ac0904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-31 16:36:06--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 54.230.31.108, 54.230.31.74, 54.230.31.76, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|54.230.31.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322405979 (307M) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_transformers.tar.gz.1’\n",
            "\n",
            "PhoBERT_base_transf 100%[===================>] 307.47M  37.7MB/s    in 4.7s    \n",
            "\n",
            "2024-07-31 16:36:11 (65.4 MB/s) - ‘PhoBERT_base_transformers.tar.gz.1’ saved [322405979/322405979]\n",
            "\n",
            "PhoBERT_base_transformers/\n",
            "PhoBERT_base_transformers/config.json\n",
            "PhoBERT_base_transformers/bpe.codes\n",
            "PhoBERT_base_transformers/model.bin\n",
            "PhoBERT_base_transformers/dict.txt\n"
          ]
        }
      ],
      "source": [
        "!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
        "!tar -xzvf PhoBERT_base_transformers.tar.gz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O0SCzInm1vsj"
      },
      "outputs": [],
      "source": [
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QRrmVWLv7ftP"
      },
      "outputs": [],
      "source": [
        "## following the instructions of phoBERT\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--bpe-codes',\n",
        "    default=\"/content/PhoBERT_base_transformers/bpe.codes\",\n",
        "    required=False,\n",
        "    type=str,\n",
        "    help='path to fastBPE BPE'\n",
        ")\n",
        "args, unknown = parser.parse_known_args()\n",
        "bpe = fastBPE(args)\n",
        "\n",
        "# Load the dictionary\n",
        "vocab = Dictionary()\n",
        "vocab.add_from_file(\"/content/PhoBERT_base_transformers/dict.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N0wjrsib7r5r",
        "outputId": "c0c2e955-0699-47b1-bdb3-401741b28056"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tôi là học sinh của trường Khoa học Tự Nhiên TP@@ HCM. Tôi thích m@@ è@@ o.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "bpe.encode('Tôi là học sinh của trường Khoa học Tự Nhiên TPHCM. Tôi thích mèo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkk-Df4I90Kb",
        "outputId": "ea7ef8a6-8943-4468-e9d1-4d0ac9cdbd8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,   218,     8,   222,   418,     7,   212,  3720,   222,  4544,\n",
              "        12567,  8656, 54251,   218,   543,  1387,  9367, 35211,     2,     2],\n",
              "       dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "vocab.encode_line('<s> ' + 'Tôi là học sinh của trường Khoa học Tự Nhiên TP@@ HCM. Tôi thích m@@ è@@ o.' + ' </s>')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1CFajKx-Kyp"
      },
      "source": [
        "`<s>` là token đặc biệt để đánh dấu vị trí đầu câu và `</s>` để đánh dấu vị trí cuối mỗi câu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "flSczBX4-N22"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "train_path = \"/content/dataSA/train.crash\"\n",
        "test_path = \"/content/dataSA/test.crash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hoLa46vLRFht"
      },
      "outputs": [],
      "source": [
        "train_id, train_text, train_label = [], [], []\n",
        "test_id, test_text = [], []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2OAfN6lR646"
      },
      "source": [
        "train_000000  \n",
        "\"Dung dc sp tot cam on  \n",
        "shop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời\"                \n",
        "0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gvYKEEIfRPbg"
      },
      "outputs": [],
      "source": [
        "with open(train_path, 'r') as f_r:\n",
        "    data = f_r.read().strip()\n",
        "    data = re.findall('train_[\\s\\S]+?\\\"\\n[01]\\n\\n', data)\n",
        "    # get the text between \" \"\n",
        "    for sample in data:\n",
        "        splits = sample.strip().split('\\n')\n",
        "\n",
        "        id = splits[0] #train_000000\n",
        "        label = int(splits[-1]) #0\n",
        "        text = ' '.join(splits[1:-1])[1:-1] # join each sentence with sapce and drop \" \"\n",
        "        text = rdrsegmenter.tokenize(text) # tokenize\n",
        "        text = ' '.join([' '.join(x) for x in text]) # join with space\n",
        "\n",
        "        train_id.append(id)\n",
        "        train_text.append(text)\n",
        "        train_label.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jeY5pHLNTlL4"
      },
      "outputs": [],
      "source": [
        "with open(test_path, 'r') as f_r:\n",
        "    data = f_r.read().strip()\n",
        "    data = re.findall('test_[\\s\\S]+?\\\"\\n\\n', data)\n",
        "    for sample in data:\n",
        "        splits = sample.strip().split('\\n')\n",
        "\n",
        "        id = splits[0]\n",
        "        text = ' '.join(splits[1:])[1:-1]\n",
        "        text = rdrsegmenter.tokenize(text)\n",
        "        text = ' '.join([' '.join(x) for x in text])\n",
        "\n",
        "        test_id.append(id)\n",
        "        test_text.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFOVDSqoT4ye",
        "outputId": "a1cfeaa8-02ad-4579-df92-c057309a4459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16071 10980\n",
            "(array([0, 1]), array([8689, 7382]))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(len(train_id),len(test_id))\n",
        "print(np.unique(train_label, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GSp4g8Ffa9kp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sents, val_sents, train_labels, val_labels = train_test_split(train_text, train_label, test_size=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Qh0kdh1pcV_u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 125\n",
        "\n",
        "train_ids = []\n",
        "for sent in train_sents:\n",
        "    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n",
        "    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
        "    train_ids.append(encoded_sent)\n",
        "\n",
        "val_ids = []\n",
        "for sent in val_sents:\n",
        "    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n",
        "    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
        "    val_ids.append(encoded_sent)\n",
        "\n",
        "train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "val_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use bpe to encode the vnmese to phrase words and use vocab to map it to its id\n",
        "\n",
        "The pad_sequences will truncated the redundant and padding to ensure that the vector will be 125 long"
      ],
      "metadata": {
        "id": "CYw5U__rprg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks = []\n",
        "for sent in train_ids:\n",
        "    mask = [int(token_id > 0) for token_id in sent]\n",
        "    train_masks.append(mask)\n",
        "\n",
        "val_masks = []\n",
        "for sent in val_ids:\n",
        "    mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    val_masks.append(mask)\n"
      ],
      "metadata": {
        "id": "rp1MrGNjqHaC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The masks (used for transformer) includes 0 and 1, tell the model which token is padding"
      ],
      "metadata": {
        "id": "yk1ShDypq8Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "\n",
        "train_inputs = torch.tensor(train_ids)\n",
        "val_inputs = torch.tensor(val_ids)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = SequentialSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)\n"
      ],
      "metadata": {
        "id": "Y1ds2MJ9qiuj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SequentialSampler is used to ensure that the data is loaded in a sequential order. This is often used during validation/testing when the order of samples matters or when you want deterministic results."
      ],
      "metadata": {
        "id": "inyqJt0BsNCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n",
        "\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n",
        ")\n",
        "BERT_SA = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/PhoBERT_base_transformers/model.bin\",\n",
        "    config=config\n",
        ")\n",
        "BERT_SA.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "eRjXUVFjrbTE",
        "outputId": "793fd31c-7624-48bb-ae4f-3674e487683c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BertForSequenceClassification' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-71251537cfb6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"/content/PhoBERT_base_transformers/config.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m BERT_SA = BertForSequenceClassification.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"/content/PhoBERT_base_transformers/model.bin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}